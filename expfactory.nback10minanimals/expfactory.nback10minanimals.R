# Apparently this is the "official" way to silence NOTEs generated by R CMD check about symbols
# in pipelines which it misperceives as globals (https://github.com/tidyverse/magrittr/issues/29).
if(getRversion() >= "2.15.1")  utils::globalVariables(c('.','p','trial_id','trial_index','rt','key_press','Sample',
                                                        'response','Wait4TUTSlide.RESP','Wait4TUTSlide.RT','add_row'))


#' Convert Experiment Factory nback-10min-animals N-Back data to CSV
#'
#' Convert Experiment Factory nback-10min-animals N-Back data to CSV
#' @param path Path to data files
#' @importFrom dplyr 
#' @export 
process_nback_data_to_csv <- function(path, t, exclude) {
  paths <-
    list.files(path,
               pattern = ".*_bc.csv",
               full.names = TRUE,
               recursive = TRUE)
  df <- process_nback_data(path)
  write.table(df$all_levels, paste(path, '/all_levels.csv', sep=''), sep = ",", row.names = FALSE)
  write.table(df$aggregated, paste(path, '/aggregated.csv', sep=''), sep = ",", row.names = FALSE)
  write.table(df$completion_times, paste(path, '/completion_times.csv', sep=''), sep = ",", row.names = FALSE)
}



#' Process nback-10min-animals N-Back data files
#'
#' \code{process_breath_counting()} processes data files generated by the nback-10min-animals N-Back task
#' (\url{https://expfactory-experiments.github.io/nback-10min-animals}).
#'

process_nback_data <- function(path) {

    keys <- list.files(path = path, full.names = TRUE, recursive = TRUE)
    keys <- keys[grepl("json", keys)]
    m <- data.frame(matrix(0, ncol = 12, nrow = 0))

    # List for holding completion times
    times <- c()
  
	# Loop through the files
	for(i in 1:length(keys)) {
  
		parts <- strsplit(keys[i],"/")[[1]]

		# Subject identifier
		## This is expecting the subject name to be in the 5th place
		## e.g., "data/nback/data/expfactory/0001"
		subj <- parts[length(parts)-1]
	  
		# File is double-encoded so we need to double-decode
		#d <- expfactory::process_expfactory_experiment(keys[i])
        d <- fromJSON(keys[i])
        d <- fromJSON(d$data)
		
		# Segment by block
		blocks <- list(
			d[which(d$exp_stage == "test" & d$block_num == 1 & d$target != ""),],
			d[which(d$exp_stage == "test" & d$block_num == 2 & d$target != ""),],
			d[which(d$exp_stage == "test" & d$block_num == 3 & d$target != ""),],
			d[which(d$exp_stage == "test" & d$block_num == 4 & d$target != ""),],
			d[which(d$exp_stage == "test" & d$block_num == 5 & d$target != ""),],
			d[which(d$exp_stage == "test" & d$block_num == 6 & d$target != ""),],
			d[which(d$exp_stage == "test" & d$block_num == 7 & d$target != ""),]
		)
		
		# Code trials for presence of target
		for(k in 1:length(blocks)) {
		  block <- blocks[k]
		  block[[1]]$has_target <- 0
		  for(x in 1:NROW(block[[1]])) {
			if(block[[1]][x,]$stim == block[[1]][x,]$target)
			  block[[1]][x,]$has_target <- 1
		  }
		  blocks[[k]] <- block[[1]]
		}
		
		# Get time spent in task
		TimeSpent <- round(d[NROW(d),]$time_elapsed/1000)
		times <- c(times, TimeSpent)
		
		# Put it all together...
		for(k in 1:length(blocks)) {
			m <- rbind(m, 
			   data.frame(
				   # Subject
				   subj,
				   
				   # N-back load
				   blocks[[k]]$load[1],
				   
				   # HITs
				   length(blocks[[k]][which(blocks[[k]]$has_target == 1 & blocks[[k]]$correct == 1),]$correct),
				   
				   # Misses
				   length(blocks[[k]][which(blocks[[k]]$has_target == 1 & blocks[[k]]$correct == 0),]$correct),
				   
				   # Correct Rejection
				   length(blocks[[k]][which(blocks[[k]]$has_target == 0 & blocks[[k]]$correct == 1),]$correct),
				   
				   # False Alarms
				   length(blocks[[k]][which(blocks[[k]]$has_target == 0 & blocks[[k]]$correct == 0),]$correct),
				   
				   # N trials
				   length(blocks[[k]]$correct),
				   
				   # N targets
				   length(blocks[[k]][which(blocks[[k]]$has_target == 1),]$correct),
				   
				   # N nontargets
				   length(blocks[[k]][which(blocks[[k]]$has_target == 0),]$correct),
				   
				   # N timeouts
				   length(blocks[[k]][which(blocks[[k]]$rt == -1),]$rt),
				   
				   # % correct attention probes
				   sum(d[which(d$trial_type == "attention-check"),]$correct)/2,
				   
				   # Mean RT
				   mean(blocks[[k]][which(blocks[[k]]$rt > -1),]$rt),
				   
				   # response deadline
				   mean(blocks[[k]]$block_duration),
				   
				   # datestamp
				   as.numeric(as.POSIXct(file.info(keys[i])[[4]])),
				   
				   stringsAsFactors = FALSE
				 )
			   )
			}
		  
		}

		# Name the columns
		colnames(m) <- c(
			"subj", 
			"load", 
			"HIT", 
			"MISS", 
			"CR", 
			"FA",
			"N",
			"Nt",
			"Nfoil",
			"Nmiss",
			"Attn",
			"M_RT",
			"Deadline",
			"Completion_time"
			)
			
		#####################################
		#####################################
		#### Aggregate and clean data

		# Aggregate by participant so we can check % timeouts
		m_agg <- m %>% 
		  group_by(subj) %>% 
		  summarise(Nmiss = sum(Nmiss), N = sum(N))

		# Keep only those with fewer than 50% timeouts (60:120 trials)
		highMissSubjects <- m_agg[which(m_agg$Nmiss > 60),]$subj
		m <- m[which(!m$subj %in% highMissSubjects),]

		# Aggregate by subject and N-back level
		m2 <- m %>% 
		  group_by(subj, load) %>% 
		  summarise(
			HIT = sum(HIT), 
			MISS = sum(MISS), 
			CR = sum(CR), 
			FA = sum(FA), 
			N = sum(N), 
			Nt = sum(Nt), 
			Nfoil = sum(Nfoil),  
			Nmiss = sum(Nmiss), 
			Attn = mean(Attn), 
			M_RT = mean(M_RT),
			Deadline = mean(Deadline),
			Completion_time = mean(Completion_time)
		  )

		# Calculate dprime on this set
		m2$dprime <- dprime(m2$HIT, m2$FA, m2$MISS, m2$CR)$dprime

		# Remove 1-back before aggregating across N-back levels
		m2_minus1 <- m2[which(m2$load > 1),]

		# Aggregate again by participant
		m3 <- m2_minus1 %>% 
		  group_by(subj) %>% 
		  summarise(
				HIT = sum(HIT), 
				MISS = sum(MISS), 
				CR = sum(CR), 
				FA = sum(FA), 
				N = sum(N), 
				Nt = sum(Nt), 
				Nfoil = sum(Nfoil),  
				Nmiss = sum(Nmiss), 
				Attn = mean(Attn),
				M_RT = mean(M_RT),
				Deadline = mean(Deadline),
				Completion_time = mean(Completion_time),
				dprime = mean(dprime))

	return(list(all_levels = m2, aggregated = m3, times = times))
}







#' Dprime and Other Signal Detection Theory indices.
#'
#' Computes Signal Detection Theory indices (d', beta, A', B''D, c).
#'
#' @param n_hit Number of hits.
#' @param n_fa Number of false alarms.
#' @param n_miss Number of misses.
#' @param n_cr Number of correct rejections.
#' @param n_targets Number of targets (n_hit + n_miss).
#' @param n_distractors Number of distractors (n_fa + n_cr).
#' @param adjusted Should it use the Hautus (1995) adjustments for extreme values.
#'
#' @return Calculates the d', the beta, the A' and the B''D based on the signal detection theory (SRT). See Pallier (2002) for the algorithms.
#'
#' Returns a list containing 4 objects:
#' \itemize{
#'  \item{\strong{dprime (d')}: }{The sensitivity. Reflects the distance between the two distributions: signal, and signal+noise and corresponds to the Z value of the hit-rate minus that of the false-alarm rate.}
#'  \item{\strong{beta}: }{The bias (criterion). The value for beta is the ratio of the normal density functions at the criterion of the Z values used in the computation of d'. This reflects an observer's bias to say 'yes' or 'no' with the unbiased observer having a value around 1.0. As the bias to say 'yes' increases (liberal), resulting in a higher hit-rate and false-alarm-rate, beta approaches 0.0. As the bias to say 'no' increases (conservative), resulting in a lower hit-rate and false-alarm rate, beta increases over 1.0 on an open-ended scale.}
#'  \item{\strong{aprime (A')}: }{Non-parametric estimate of discriminability. An A' near 1.0 indicates good discriminability, while a value near 0.5 means chance performance.}
#'  \item{\strong{bppd (B''D)}: }{Non-parametric estimate of bias. A B''D equal to 0.0 indicates no bias, positive numbers represent conservative bias (i.e., a tendency to answer 'no'), negative numbers represent liberal bias (i.e. a tendency to answer 'yes'). The maximum absolute value is 1.0.}
#'  \item{\strong{c}: }{Another index of bias. the number of standard deviations from the midpoint between these two distributions, i.e., a measure on a continuum from "conservative" to "liberal".}
#'  }
#'
#'
#' Note that for d' and beta, adjustement for extreme values are made following the recommandations of Hautus (1995).


#' @examples
#' library(psycho)
#'
#' n_hit <- 9
#' n_fa <- 2
#' n_miss <- 1
#' n_cr <- 7
#'
#' indices <- psycho::dprime(n_hit, n_fa, n_miss, n_cr)
#'
#'
#' df <- data.frame(Participant = c("A", "B", "C"),
#'     n_hit = c(1, 2, 5),
#'     n_fa = c(6, 8, 1))
#'
#' indices <- psycho::dprime(n_hit=df$n_hit,
#'     n_fa=df$n_fa,
#'     n_targets=10,
#'     n_distractors=10,
#'     adjusted=FALSE)
#'
#'
#' @author \href{https://dominiquemakowski.github.io/}{Dominique Makowski}
#'
#' @importFrom stats qnorm
#' @export
dprime <- function(n_hit, n_fa, n_miss=NULL, n_cr=NULL, n_targets=NULL, n_distractors=NULL, adjusted=TRUE) {
  if (is.null(n_targets)) {
    n_targets <- n_hit + n_miss
  }

  if (is.null(n_distractors)) {
    n_distractors <- n_fa + n_cr
  }


  # Parametric Indices ------------------------------------------------------


  if (adjusted == TRUE) {
    if (is.null(n_miss) | is.null(n_cr)) {
      warning("Please provide n_miss and n_cr in order to compute adjusted ratios. Computing indices anyway with non-adjusted ratios...")

      # Non-Adjusted ratios
      hit_rate_adjusted <- n_hit / n_targets
      fa_rate_adjusted <- n_fa / n_distractors
    } else {
      # Adjusted ratios
      hit_rate_adjusted <- (n_hit + 0.5) / ((n_hit + 0.5) + n_miss + 1)
      fa_rate_adjusted <- (n_fa + 0.5) / ((n_fa + 0.5) + n_cr + 1)
    }

    # dprime
    dprime <- qnorm(hit_rate_adjusted) - qnorm(fa_rate_adjusted)

    # beta
    zhr <- qnorm(hit_rate_adjusted)
    zfar <- qnorm(fa_rate_adjusted)
    beta <- exp(-zhr * zhr / 2 + zfar * zfar / 2)

    # c
    c <- -(qnorm(hit_rate_adjusted) + qnorm(fa_rate_adjusted)) / 2
  } else {
    # Ratios
    hit_rate <- n_hit / n_targets
    fa_rate <- n_fa / n_distractors

    # dprime
    dprime <- qnorm(hit_rate) - qnorm(fa_rate)

    # beta
    zhr <- qnorm(hit_rate)
    zfar <- qnorm(fa_rate)
    beta <- exp(-zhr * zhr / 2 + zfar * zfar / 2)

    # c
    c <- -(qnorm(hit_rate) + qnorm(fa_rate)) / 2
  }

  # Non-Parametric Indices ------------------------------------------------------

  # Ratios
  hit_rate <- n_hit / n_targets
  fa_rate <- n_fa / n_distractors

  # aprime
  a <- 1 / 2 + ((hit_rate - fa_rate) * (1 + hit_rate - fa_rate) / (4 * hit_rate * (1 - fa_rate)))
  b <- 1 / 2 - ((fa_rate - hit_rate) * (1 + fa_rate - hit_rate) / (4 * fa_rate * (1 - hit_rate)))

  a[fa_rate > hit_rate] <- b[fa_rate > hit_rate]
  a[fa_rate == hit_rate] <- .5
  aprime <- a

  # bppd
  bppd <- ((1 - hit_rate) * (1 - fa_rate) - hit_rate * fa_rate) / ((1 - hit_rate) * (1 - fa_rate) + hit_rate * fa_rate)


  return(list(dprime = dprime, beta = beta, aprime = aprime, bppd = bppd, c = c))
}
